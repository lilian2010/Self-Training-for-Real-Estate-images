{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imoport some packages to use \n",
    "import os\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Input, Dense, Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "#from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def vgg19_model(img_rows, img_cols, channel=3, num_classes=None):\n",
    "\n",
    "    model = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "    model.layers.pop()\n",
    "\n",
    "   # model.outputs = [model.layers[-1].output]\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    #model.layers[-1].outbound_nodes = []\n",
    "    model.layers[-1].outbound_node = []\n",
    "\n",
    "  #  model.output = tensorflow.keras.layers.Flatten()(model.outputs)\n",
    "    x=Dense(num_classes, activation='softmax')(model.output)\n",
    "\n",
    "    model=Model(model.input,x)\n",
    "\n",
    "#To set the first 8 layers to non-trainable (weights will not be updated)\n",
    "\n",
    "    for layer in model.layers[:8]:\n",
    "\n",
    "       layer.trainable = False\n",
    "\n",
    "# Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "nb_epoch = 100\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 2\n",
    "\n",
    "batch_size = 64\n",
    "model = vgg19_model(img_rows, img_cols, channel, num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imageRawDir):\n",
    "    \"\"\"\n",
    "    images preprocess\n",
    "\n",
    "    Arguments:\n",
    "    imageRawDir -- directory of primary images.\n",
    "    \n",
    "\n",
    "    Return: preprocessed images and labels.\n",
    "    \"\"\"\n",
    "    imageNames = os.listdir(imageRawDir)\n",
    "    img=np.zeros(shape=(len(imageNames), 224 ,224,3))\n",
    "    label=[]\n",
    "    \n",
    "    #label = read_and_process_images() # directory format：\"./data/cat/\"\n",
    "    for index, imageName in enumerate(imageNames):\n",
    "        #print(imageName)\n",
    "        image = Image.open(os.path.join(imageRawDir,imageName))\n",
    "        image=np.array(image) \n",
    "        image=preprocess_input(image)\n",
    "        img[index]=image\n",
    "        label_1= imageName.split(\"_\")[0]\n",
    "        label_2 = label_1.split(\"ion\")[1]\n",
    "        if(label_2=='1'):\n",
    "         #   print('switch')\n",
    "            label_2='0'\n",
    "        if(label_2=='2'):\n",
    "         #   print('switch')\n",
    "            label_2='0'\n",
    "        if(label_2=='3'):\n",
    "         #   print('switch')\n",
    "            label_2='1'\n",
    "        if(label_2=='4'):\n",
    "         #   print('switch')\n",
    "            label_2='1'\n",
    "        label.append(label_2)\n",
    "        #print(label)\n",
    "       # label.append(imageName.split(\"_\")[0])\n",
    "        \n",
    "      \n",
    "    return img,label\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_unlabel(imageRawDir):\n",
    "    \"\"\"\n",
    "    images preprocess\n",
    "\n",
    "    Arguments:\n",
    "    imageRawDir -- directory of primary images.\n",
    "    \n",
    "\n",
    "    Return: preprocessed images.\n",
    "    \"\"\"\n",
    "    imageNames = os.listdir(imageRawDir)\n",
    "    img=np.zeros(shape=(len(imageNames), 224 ,224,3))\n",
    "   # label=[]\n",
    "    \n",
    "    #label = read_and_process_images() # directory format：\"./data/cat/\"\n",
    "    for index, imageName in enumerate(imageNames):\n",
    "        #print(imageName)\n",
    "        image = Image.open(os.path.join(imageRawDir,imageName))\n",
    "        image=np.array(image) \n",
    "        image=preprocess_input(image)\n",
    "        img[index]=image\n",
    "        \n",
    "        #print(label)\n",
    "       # label.append(imageName.split(\"_\")[0])\n",
    "        \n",
    "      \n",
    "    return img\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_y(y):\n",
    "    y=np.array(y)\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "    y=to_categorical(y)\n",
    "    y=np.array(y)\n",
    "    print(y.shape)\n",
    "    return(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"condition_aug_train/\"\n",
    "train_img,train_y = preprocess(train_dir)\n",
    "train_y=encode_y(train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.20, random_state=42)\n",
    "del(train_img,train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras import callbacks\n",
    "start = datetime.now()\n",
    "es_callback =tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,shuffle=True,verbose=1,validation_data=(X_valid, Y_valid),callbacks=[es_callback])\n",
    "end = datetime.now()\n",
    "print('Traning the Fine Tune model:', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs =  range(1,len(acc)+1)\n",
    "\n",
    "#train and validation accuracy \n",
    "plt.plot(epochs, acc, 'b', label ='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label ='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label ='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label ='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "#plt.title('Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"condition_aug_test/\"\n",
    "test_img,test_y= preprocess(test_dir)\n",
    "test_y = encode_y(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_img, test_y, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred_y = model.predict(test_img)\n",
    "pred_class = np.argmax(pred_y, axis=1)\n",
    "test_class= np.argmax(test_y, axis=1)\n",
    "score = accuracy_score(test_class, pred_class)\n",
    "print(score)\n",
    "confusion_matrix(test_class,pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(test_img, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabel_dir =\"unlabel_part/\"\n",
    "unlabel_img = preprocess_unlabel(unlabel_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labeles = model.predict(unlabel_img)\n",
    "pseudo_labeles.shape\n",
    "pseudo_idx = np.argmax(pseudo_labeles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "number_image = [0,0,0,0,0]\n",
    "select_train_y  = []\n",
    "select_train_img=[]\n",
    "for i in range(0,len(pseudo_labeles)):\n",
    "    pseudo_label = pseudo_idx[i]\n",
    "    confidence = pseudo_labeles[i][pseudo_label]\n",
    "    confidence_per_class = [0.95,0.95,0.95,0.95,0.95]\n",
    "    if pseudo_labeles[i][pseudo_label]>=confidence_per_class[pseudo_label]:\n",
    "        select_train_y.append(pseudo_label)\n",
    "        select_train_img.append(unlabel_img[i])\n",
    "        number_image[pseudo_label] +=1\n",
    "print(number_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(unlabel_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train_y = encode_y(select_train_y )\n",
    "select_train_img = np.array(select_train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"condition_aug_train/\"\n",
    "train_img,train_y = preprocess(train_dir)\n",
    "train_y=encode_y(train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_img = np.concatenate((train_img, select_train_img))\n",
    "result_y = np.concatenate((train_y, select_train_y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train_img,train_y,select_train_img,select_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(result_img,result_y,test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(result_img, result_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras import callbacks\n",
    "start = datetime.now()\n",
    "es_callback =tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=32,validation_data=(X_valid,Y_valid),callbacks=[es_callback])\n",
    "end = datetime.now()\n",
    "print('Traning the Fine Tune model:', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(result_img,result_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"condition_aug_test/\"\n",
    "test_img,test_y= preprocess(test_dir)\n",
    "test_y = encode_y(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_img, test_y, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred_y = model.predict(test_img)\n",
    "pred_class = np.argmax(pred_y, axis=1)\n",
    "test_class= np.argmax(test_y, axis=1)\n",
    "score = accuracy_score(test_class, pred_class)\n",
    "print(score)\n",
    "confusion_matrix(test_class,pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(test_img, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
    "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
    "                                   horizontal_flip=True, fill_mode='nearest',preprocessing_function=None)\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, Y_train,batch_size=32)\n",
    "val_generator = val_datagen.flow(X_valid, Y_valid, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras import callbacks\n",
    "start = datetime.now()\n",
    "nb_epoch = 60\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import callbacks\n",
    "import random\n",
    "start = datetime.now()\n",
    "nb_epoch = 60\n",
    "\n",
    "\n",
    "\n",
    "es_callback =tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "#history = model.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,shuffle=True,verbose=1,validation_data=(X_valid, Y_valid),callbacks=[es_callback])\n",
    "history = model.fit_generator(train_generator, \n",
    "                             steps_per_epoch=200, \n",
    "                              epochs=200,\n",
    "                             validation_data=val_generator, \n",
    "                              validation_steps=50, \n",
    "                              callbacks=[es_callback],\n",
    "                              shuffle=True,\n",
    "                              verbose=1)\n",
    "\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = 1./255*test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_img, test_y, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred_y = model.predict(test_img)\n",
    "pred_class = np.argmax(pred_y, axis=1)\n",
    "test_class= np.argmax(test_y, axis=1)\n",
    "score = accuracy_score(test_class, pred_class)\n",
    "print(score)\n",
    "confusion_matrix(test_class,pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
